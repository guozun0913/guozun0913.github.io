---


layout: post
title:  "yolov5算法笔记2"
date:   2024-4-23 10:01:30 +0800--
categories: [算法]
tags: [yolov5]  
---

### YOLO算法笔记2：架构与组件

2.1 yolov5单阶段检测器

| YOLOv5包括模块 |                                 |
| -------------- | ------------------------------- |
| Backbone       | Focus, BottleneckCSP, SPP       |
| Head           | PANet + Detect (YOLOv3/v4 Head) |

2.2 网络结构可视化工具：netron

![](https://img2.imgtp.com/2024/04/22/Kz9z0QBr.png)

​		netron对pt格式的权重文件兼容性不好，直接使用netron工具打开，无法显示
整个网络。
​		可使用YOLOv5代码中models/export.py脚本将pt权重文件转换为onnx格式,
再用netron工具打开，就可以看YOLOv5网络的整体架构 :

pip install onnx>=1.7.0 -i https:// pypituna.tsinghua.edu.cn/simple # for ONNX export

pip install coremltools==4.0 -i https:// pypi.tuna.tsinghua.edu.cn/simple # for CoreML export

python models/ export.py --weights weights/yolov5s.pt --img 640 --batch 1



权重文件打开后可以看到具体网络的具体结构：

![](https://img2.imgtp.com/2024/04/22/7wnx67OO.png)

2.3 yaml网络模型配置文件代码分析

![](https://img2.imgtp.com/2024/04/22/J6xoazpj.png)

|                                | 理解                                                         |
| ------------------------------ | ------------------------------------------------------------ |
| depth_multiple                 | 网络的深度，即网络中层级的数量或者深度的倍数。通过调整这个参数，可以增加或减少网络的层数，从而影响网络的感知范围和复杂度。 |
| width_multiple                 | 整网络的宽度，通常指的是网络中每个层级的通道数或特征图的宽度的倍数。增加或减少这个参数可以改变网络的表征能力和计算复杂度。 |
| 二者关系                       | 参数的调整通常是为了平衡网络的性能和计算资源之间的关系，以便在满足目标检测任务需求的同时，尽可能地提高算法的效率和速度。 |
| anchors                        | 锚框预测预设的参数，p3/8表示8倍下采样                        |
| 步长（stride）                 | 代表了在卷积操作中滑动窗口的步幅，也就是在进行卷积操作时，卷积核每次在特征图上移动的距离。步长通常用来控制特征图的尺寸缩放以及感受野（receptive field）的大小。较大的步长会导致特征图尺寸减小，同时感受野增大，从而使得网络更多地关注全局信息，适合用来检测较大的物体或者获取较为宏观的场景信息。相反，较小的步长会使得特征图尺寸增加，感受野减小，更适合用来检测较小的物体或者获取更为局部的特征信息 |
| 卷积核（convolutional kernel） | 它是一个小的、可学习的、用于从输入数据中提取特征的滤波器。卷积核通过与输入数据进行卷积操作，从而产生输出特征图，其中每个元素代表了输入数据的某种特征在空间上的响应。 |

| 卷积核的作用                                                 |
| ------------------------------------------------------------ |
| 1.特征提取：卷积核通过在输入数据上进行滑动卷积操作，可以提取输入数据中的各种特征，例如边缘、纹理、形状等。 |
| 2.特征映射：每个卷积核都会生成一个特征映射（feature map），其中的每个元素代表了输入数据中某个位置的特征。通过使用多个卷积核，可以生成多个特征映射，从而捕捉输入数据的不同方面的特征。 |
| 3.参数学习：卷积核的权重参数是可以学习的，通过反向传播算法和优化算法（如梯度下降），网络可以自动调整这些参数，从而使得卷积核能够适应不同的特征提取任务。 |
| 4.稀疏交互：卷积操作具有局部连接和参数共享的特性，这使得网络在处理大规模数据时具有较高的计算效率，并且可以有效地处理高维数据，如图像和文本数据。 |
| 卷积核在卷积神经网络中通过特征提取和参数学习，帮助网络有效地从原始数据中学习和表示复杂的特征信息。 |

2.4backbone主干网络

![](https://img2.imgtp.com/2024/04/22/FhU057Vy.png)

|                 |                                                              |
| --------------- | ------------------------------------------------------------ |
| focus           | 用于处理输入数据的前期预处理。它可以用来实现对输入数据的尺寸调整、特征提取或者通道变换等操作 |
| Conv 模块       | 卷积操作的基本组成单元，用于在神经网络中进行特征提取。Conv 模块通过卷积核在输入数据上的滑动操作，实现从输入数据中提取特征的功能。它通常包括卷积层、激活函数和池化层等组件，用于对输入数据进行特征提取和降维 |
| Bottleneck 模块 | 用于减少模型参数数量和计算复杂度，同时保持模型的表征能力。这种模块通常由一个较窄的卷积层和一个较宽的卷积层组成，通过在两者之间加入一个 1x1 的卷积层，可以实现特征降维和通道数的调整，从而在保持模型效果的同时减少了计算量 |



![](https://img2.imgtp.com/2024/04/22/bnmZemqq.png)

|              |      |
| ------------ | ---- |
| Upsample | 上采样操作用于增加特征图的尺寸。在深度学习中，上采样常用于将低分辨率特征图恢复到原始输入图像的尺寸，通常通过插值等方法实现 |
| Concatenation(concat) | 连接操作将多个特征图按照指定的维度进行拼接。这在神经网络中常用于将来自不同层或分支的特征组合起来，以提供更丰富的信息给接下来的层次。 |

| 思考                   |                                                              |
| ---------------------- | ------------------------------------------------------------ |
| 哪些需要乘以缩放因子？ | depth_multiple*conv控制不同模型的深度 。width_multiple需要乘以哪些？ |

2.4 yolov5s模型在netron里的表示

![](https://img2.imgtp.com/2024/04/22/4nuB70wQ.png)

|                     |                                                              |
| ------------------- | ------------------------------------------------------------ |
| conv                | 卷积操作，它用于从输入数据中提取特征                         |
| BN(批量归一化)      | 用于提高神经网络的训练稳定性和加速收敛,通过在每个批次的数据上进行归一化处理，使得网络的输入分布更加稳定，有助于加速训练过程 |
| hardwish( 激活函数) | 一种类似于 Swish 激活函数的非线性函数，具有更好的计算性能和梯度特性.常用于引入非线性，增强模型的表达能力 |
| shortcut            | 是一种残差连接（Residual Connection）的形式，也称为跳跃连接（Skip Connection）。它允许网络在不同层次之间直接连接，从而有助于减轻梯度消失问题和加速训练过程 |

![](https://img2.imgtp.com/2024/04/22/OW5zwzCQ.png)

![](https://img2.imgtp.com/2024/04/22/5zlBS3w1.png)

​		这个输入转换的过程是为了在 YOLOv5 中减少卷积操作的计算量，并通过张量重塑来减少空间（分辨率）并增加深度（通道数）。

​		具体地，输入会被转换如下： 原始输入形状为 [批大小, 通道数, 高度, 宽度] 转换后的形状为 [批大小, 通道数×4, 高度除以2, 宽度除以2]这意味着原始输入的高度和宽度会被缩小一半，而通道数会增加为原来的四倍。这种转换有助于减少计算量，提高模型的速度和效率。#把宽度w和高度h的信息整合到c空间中

​		以Yolov5s的结构为例，原始640x640x3的图像输入Focus结构,采用切片操作，先变成320x320x12的
特征图，再经过一次32个卷 积核的卷积操作,最终变成320x320x32的特征图。

而yolov5m的Focus结构中的卷积操作使用了48个卷积核，因此Focus结构后的特征图变成320x320x48。
yolov5l, yolov5x也是同样的原理

| focus的作用  |                                                              |
| ------------ | ------------------------------------------------------------ |
| 减少计算量   | 可以在保持感兴趣区域信息的同时，减少整体的计算量。它可以帮助网络更加专注地处理与目标相关的区域，从而提高运行速度和效率 |
| 增强感知能力 | 可以增强网络对感兴趣区域的感知能力，使其更好地理解目标的位置和特征。这有助于提高目标检测的准确性和稳定性 |
| 加速收敛     | 通过专门处理感兴趣区域，`focus` 层可以加速网络的收敛过程。这有助于更快地训练模型，并提高模型的性能 |

2.5 CSPNET

![](https://img2.imgtp.com/2024/04/22/T3sZvhGc.png)

| bottleneck CSP                               |                                                              |
| -------------------------------------------- | ------------------------------------------------------------ |
| 瓶颈结构(Bottleneck Structure)               | 瓶颈结构是一种常见于深度神经网络中的模块，它通过使用少量的通道数来降低计算复杂度，同时保持特征图的维度。这有助于减少模型的参数数量和计算量，同时提高模型的效率 |
| 交叉阶段连接（Cross Stage Partial Connection | 交叉阶段连接是指在模块内部和模块之间引入的连接，用于增强信息流动和特征融合。在 bottleneck CSP 中，交叉阶段连接可以帮助不同阶段的特征相互影响和交换信息，从而提高模型的表达能力 |
| 空间金字塔池化（Spatial Pyramid Pooling）    | bottleneck CSP 中通常会包含空间金字塔池化操作，用于捕获不同尺度的特征。这有助于提高模型对目标的多尺度感知能力，从而增强目标检测的准确性 |
|                                              | 网络模块，用于增强模型的表达能力和减少计算量。它结合了瓶颈结构（bottleneck）和交叉阶段连接（Cross Stage Partial）的特性，以提高模型的性能 |



![](https://img2.imgtp.com/2024/04/22/zADDuc4W.png)

2.6 SPP空间金字塔池化

![](https://img2.imgtp.com/2024/04/26/mXL8NC6D.png)

SPP（Spatial Pyramid Pooling）网络的作用是允许网络处理不同尺度的输入图像而不需要改变网络结构。具体来说，SPP网络通过在不同层次上对输入图像进行不同大小的池化操作，生成固定大小的特征向量，这样无论输入图像的尺寸如何，都能够得到固定大小的特征表示。

2.7 路径聚合网络

![](https://img2.imgtp.com/2024/04/26/i3RRSOjr.png)

 PANet（Path Aggregation Network）的作用是提高目标检测的性能，特别是在处理小目标和密集目标时。PANet引入了自顶向下和自底向上的路径，以有效地聚合不同特征层次的信息。具体来说，PANet包含了两个关键模块：自顶向下的上采样路径和自底向上的自适应特征池化（adaptive feature pooling）路径。这些路径允许网络在不同层次上整合语义信息和位置信息，从而提高了目标检测的准确性，特别是在复杂场景下。
